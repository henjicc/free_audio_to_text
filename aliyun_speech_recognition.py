#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«å·¥å…·
ä½¿ç”¨DashScope SDKè°ƒç”¨SenseVoiceå½•éŸ³è¯­éŸ³è¯†åˆ«æœåŠ¡
"""

import os
import sys
import json
import argparse
import requests
import re
from http import HTTPStatus
from typing import List, Optional, Dict, Any
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å¯¼å…¥DashScope SDK
try:
    import dashscope
    from dashscope.audio.asr import Transcription
except ImportError:
    print("âŒ é”™è¯¯: æœªå®‰è£…DashScope SDK")
    print("è¯·é€šè¿‡ä»¥ä¸‹å‘½ä»¤å®‰è£…: pip install dashscope")
    sys.exit(1)

class AliyunSpeechRecognition:
    """é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«å·¥å…·ç±»"""
    
    def __init__(self, api_key: Optional[str] = None, remove_tags: bool = True):
        """
        åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å·¥å…·
        
        å‚æ•°:
            api_key: é˜¿é‡Œäº‘APIå¯†é’¥ï¼Œä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡è·å–
            remove_tags: æ˜¯å¦ç§»é™¤æƒ…æ„Ÿå’ŒéŸ³é¢‘äº‹ä»¶æ ‡è®°ï¼Œé»˜è®¤ä¸ºTrue
        """
        # è·å–APIå¯†é’¥(ä¼˜å…ˆçº§ï¼šå‚æ•° > ç¯å¢ƒå˜é‡)
        self.api_key = api_key or os.environ.get("DASHSCOPE_API_KEY")
            
        if not self.api_key:
            raise ValueError("ç¼ºå°‘é˜¿é‡Œäº‘APIå¯†é’¥ï¼Œè¯·åœ¨å‚æ•°ä¸­æä¾›æˆ–è®¾ç½®DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
        
        # è®¾ç½®APIå¯†é’¥
        dashscope.api_key = self.api_key
        
        # æ˜¯å¦ç§»é™¤æ ‡è®°
        self.remove_tags = remove_tags
    
    def recognize_file(self, file_url: str, language: str = 'auto', verbose: bool = False) -> Dict[str, Any]:
        """
        è¯†åˆ«éŸ³é¢‘æ–‡ä»¶å†…å®¹
        
        å‚æ•°:
            file_url: éŸ³é¢‘æ–‡ä»¶URLï¼ˆå¿…é¡»æ˜¯å¯å…¬ç½‘è®¿é—®çš„URLï¼‰
            language: è¯­è¨€ä»£ç ï¼Œé»˜è®¤ä¸ºautoè‡ªåŠ¨æ£€æµ‹
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
            
        è¿”å›:
            è¯†åˆ«ç»“æœå­—å…¸
        """
        if verbose:
            print(f"ğŸ” å¼€å§‹è¯†åˆ«éŸ³é¢‘: {file_url}")
            print(f"ğŸŒ è¯†åˆ«è¯­è¨€è®¾ç½®: {language}")
        
        # æäº¤å¼‚æ­¥è¯†åˆ«ä»»åŠ¡
        try:
            # æ„å»ºè¯­è¨€æç¤ºåˆ—è¡¨
            language_hints = [language]
            
            # è°ƒç”¨å¼‚æ­¥APIæäº¤ä»»åŠ¡
            task_response = Transcription.async_call(
                model='sensevoice-v1',
                file_urls=[file_url],
                language_hints=language_hints
            )
            
            if verbose:
                print(f"âœ… ä»»åŠ¡æäº¤æˆåŠŸï¼Œä»»åŠ¡ID: {task_response.output.task_id}")
                print(f"â³ ä»»åŠ¡çŠ¶æ€: {task_response.output.task_status}")
                print("â³ æ­£åœ¨ç­‰å¾…ä»»åŠ¡å®Œæˆ...")
            
            # åŒæ­¥ç­‰å¾…ä»»åŠ¡å®Œæˆ
            transcribe_response = Transcription.wait(task=task_response.output.task_id)
            
            if transcribe_response.status_code == HTTPStatus.OK:
                if verbose:
                    print(f"âœ… ä»»åŠ¡å®Œæˆï¼ŒçŠ¶æ€: {transcribe_response.output.task_status}")
                
                # è¿”å›ä»»åŠ¡ç»“æœ
                return self._process_transcription_result(transcribe_response.output, verbose)
            else:
                print(f"âŒ é”™è¯¯: APIè¿”å›é”™è¯¯çŠ¶æ€ç  {transcribe_response.status_code}")
                return {"error": f"APIè¿”å›é”™è¯¯çŠ¶æ€ç : {transcribe_response.status_code}"}
                
        except Exception as e:
            print(f"âŒ è¯†åˆ«å¤±è´¥: {str(e)}")
            return {"error": str(e)}
    
    def _clean_text(self, text: str) -> str:
        """
        æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤æƒ…æ„Ÿå’ŒéŸ³é¢‘äº‹ä»¶æ ‡è®°
        
        å‚æ•°:
            text: åŸå§‹è¯†åˆ«æ–‡æœ¬
            
        è¿”å›:
            æ¸…ç†åçš„æ–‡æœ¬
        """
        # å¦‚æœä¸éœ€è¦ç§»é™¤æ ‡è®°ï¼Œç›´æ¥è¿”å›åŸå§‹æ–‡æœ¬
        if not self.remove_tags:
            return text
        
        # ç§»é™¤æ‰€æœ‰å°–æ‹¬å·åŠå…¶å†…å®¹ <...>
        text = re.sub(r'<[^>]*>', '', text)
        
        # ç§»é™¤æƒ…æ„Ÿæ ‡è®° (|HAPPY|, |SAD|, |ANGRY|, |NEUTRAL| ç­‰)
        text = re.sub(r'\|[A-Z]+\|', '', text)
        
        # ç§»é™¤éŸ³é¢‘äº‹ä»¶æ ‡è®° (|Applause|...|/Applause| ç­‰)
        # å…ˆç§»é™¤äº‹ä»¶ç»“æŸæ ‡è®°
        text = re.sub(r'\|/[A-Za-z]+\|', '', text)
        # å†ç§»é™¤äº‹ä»¶å¼€å§‹æ ‡è®°
        text = re.sub(r'\|[A-Za-z]+\|', '', text)
        
        # ç§»é™¤å¤šä½™ç©ºæ ¼
        text = re.sub(r'\s+', ' ', text)
        text = text.strip()
        
        return text
    
    def _process_transcription_result(self, output, verbose: bool = False) -> Dict[str, Any]:
        """å¤„ç†è½¬å½•ç»“æœ"""
        result = {}
        
        if output.task_status != "SUCCEEDED":
            if verbose:
                print(f"âš ï¸ ä»»åŠ¡æœªæˆåŠŸå®Œæˆï¼ŒçŠ¶æ€: {output.task_status}")
            return {"error": f"ä»»åŠ¡çŠ¶æ€: {output.task_status}"}
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç»“æœ
        if not hasattr(output, 'results') or not output.results:
            return {"error": "æ²¡æœ‰è¯†åˆ«ç»“æœ"}
        
        # å¤„ç†æ¯ä¸ªå­ä»»åŠ¡çš„ç»“æœ
        all_texts = []
        clean_texts = []
        for idx, item in enumerate(output.results):
            if item.get('subtask_status') != "SUCCEEDED":
                if verbose:
                    print(f"âš ï¸ å­ä»»åŠ¡ {idx+1} å¤±è´¥: {item.get('message', 'æœªçŸ¥é”™è¯¯')}")
                continue
            
            # è·å–è¯†åˆ«ç»“æœURL
            transcription_url = item.get('transcription_url')
            if not transcription_url:
                continue
                
            try:
                # ä¸‹è½½è¯†åˆ«ç»“æœ
                if verbose:
                    print(f"ğŸ“¥ ä¸‹è½½è¯†åˆ«ç»“æœ: {transcription_url}")
                    
                response = requests.get(transcription_url)
                response.raise_for_status()
                
                # è§£æJSONç»“æœ
                transcript_data = response.json()
                
                # æå–æ–‡æœ¬å†…å®¹
                if 'transcripts' in transcript_data and transcript_data['transcripts']:
                    for transcript in transcript_data['transcripts']:
                        if 'text' in transcript:
                            # ä¿å­˜åŸå§‹æ–‡æœ¬
                            original_text = transcript['text']
                            all_texts.append(original_text)
                            
                            # æ¸…ç†æ–‡æœ¬å¹¶ä¿å­˜
                            clean_text = self._clean_text(original_text)
                            clean_texts.append(clean_text)
                
                # ä¿å­˜è¯¦ç»†ç»“æœ
                if idx == 0:  # åªä¿å­˜ç¬¬ä¸€ä¸ªæ–‡ä»¶çš„è¯¦ç»†ä¿¡æ¯
                    result['details'] = transcript_data
                
            except Exception as e:
                if verbose:
                    print(f"âŒ ä¸‹è½½æˆ–è§£æè¯†åˆ«ç»“æœå¤±è´¥: {str(e)}")
        
        # åˆå¹¶æ‰€æœ‰æ–‡æœ¬
        result['original_text'] = "\n".join(all_texts)
        result['text'] = "\n".join(clean_texts)
        
        return result

def process_recognition_result(result_json, keep_tags=False):
    """
    å¤„ç†è¯†åˆ«ç»“æœï¼Œæ ¹æ®éœ€è¦å»é™¤æ ‡è®°
    
    å‚æ•°:
        result_json: APIè¿”å›çš„JSONç»“æœ
        keep_tags: æ˜¯å¦ä¿ç•™æƒ…æ„Ÿå’ŒéŸ³é¢‘äº‹ä»¶æ ‡è®°
        
    è¿”å›:
        å¤„ç†åçš„æ–‡æœ¬å’ŒåŸå§‹æ–‡æœ¬
    """
    # è·å–åŸå§‹æ–‡æœ¬
    original_text = result_json.get('text', '')
    
    # å¦‚æœéœ€è¦ä¿ç•™æ ‡è®°ï¼Œç›´æ¥è¿”å›åŸå§‹æ–‡æœ¬
    if keep_tags:
        return original_text, original_text
    
    # å¦åˆ™å¤„ç†æ–‡æœ¬ï¼Œå»é™¤æ‰€æœ‰æ ‡è®°
    processed_text = original_text
    # ç§»é™¤æ‰€æœ‰å°–æ‹¬å·åŠå…¶å†…å®¹
    processed_text = re.sub(r'<[^>]*>', '', processed_text)
    # å»é™¤å…¶ä»–ç±»å‹çš„æ ‡è®°
    processed_text = re.sub(r'\[.*?\]', '', processed_text)
    processed_text = re.sub(r'\|[A-Z]+\|', '', processed_text)
    processed_text = re.sub(r'\|/[A-Za-z]+\|', '', processed_text)
    processed_text = re.sub(r'\|[A-Za-z]+\|', '', processed_text)
    
    return processed_text, original_text

def main():
    """ä¸»å‡½æ•°ï¼Œå¤„ç†å‘½ä»¤è¡Œå‚æ•°å¹¶æ‰§è¡Œè¯­éŸ³è¯†åˆ«"""
    # åˆ›å»ºå‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser(description="é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«å·¥å…·")
    parser.add_argument("url", help="éŸ³é¢‘æ–‡ä»¶URLï¼ˆå¿…é¡»æ˜¯å¯å…¬ç½‘è®¿é—®çš„URLï¼‰")
    parser.add_argument("-k", "--api-key", help="é˜¿é‡Œäº‘APIå¯†é’¥")
    parser.add_argument("-l", "--language", default="auto", help="è¯­è¨€ä»£ç ï¼Œé»˜è®¤ä¸ºautoè‡ªåŠ¨æ£€æµ‹")
    parser.add_argument("-v", "--verbose", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯")
    parser.add_argument("-o", "--output", help="ä¿å­˜è¯†åˆ«ç»“æœçš„JSONæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--keep-tags", action="store_true", help="ä¿ç•™æƒ…æ„Ÿå’ŒéŸ³é¢‘äº‹ä»¶æ ‡è®°")
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parser.parse_args()
    
    # åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å·¥å…·
    recognizer = AliyunSpeechRecognition(
        api_key=args.api_key,
        remove_tags=not args.keep_tags
    )
    
    # æ‰§è¡Œè¯­éŸ³è¯†åˆ«
    result = recognizer.recognize_file(
        file_url=args.url,
        language=args.language,
        verbose=args.verbose
    )
    
    # å¤„ç†ç»“æœ
    if "error" in result:
        print(f"âŒ è¯†åˆ«å¤±è´¥: {result['error']}")
        sys.exit(1)
    
    # æ˜¾ç¤ºè¯†åˆ«æ–‡æœ¬
    print("\nğŸ“ è¯†åˆ«ç»“æœ:")
    print("-" * 60)
    print(result["text"])
    print("-" * 60)
    
    # å¦‚æœä¿ç•™äº†æ ‡è®°ï¼Œæ˜¾ç¤ºåŸå§‹æ–‡æœ¬
    if args.keep_tags and "original_text" in result:
        print("\nğŸ“ åŸå§‹è¯†åˆ«ç»“æœ (åŒ…å«æ ‡è®°):")
        print("-" * 60)
        print(result["original_text"])
        print("-" * 60)
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    if args.output:
        try:
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"âœ… å®Œæ•´ç»“æœå·²ä¿å­˜è‡³: {args.output}")
        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {str(e)}")
    
if __name__ == "__main__":
    main() 